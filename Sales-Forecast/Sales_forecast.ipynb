{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from multiprocess import Pool\n",
    "from joblib import Parallel, delayed\n",
    "import datetime\n",
    "import itertools\n",
    "import psutil\n",
    "#import jupyternotify\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "#import cufflinks as cf\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as s\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import xgboost as xgb\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from fbprophet import Prophet\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' \n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cpus = psutil.cpu_count(logical=False)\n",
    "num_cpus\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional store data\n",
    "store = pd.read_csv('store.csv')\n",
    "\n",
    "# Importing train data to learn and test data\n",
    "train = pd.read_csv('train.csv', parse_dates = True, index_col = 'Date', low_memory = False)\n",
    "test = pd.read_csv('test.csv', parse_dates = True, index_col = 'Date', low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan values from column 'Open'\n",
    "\n",
    "zero_index = test[test['Open'] == 0.00]\n",
    "one_index = test[test['Open'] == 1.00]\n",
    "test = pd.concat([zero_index,one_index])\n",
    "test['Open'] = test.Open.astype(int)\n",
    "#test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.isnull().sum()\n",
    "store['CompetitionDistance'] = store['CompetitionDistance'].fillna(store['CompetitionDistance'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Promo = No Promo since week/year \n",
    "\n",
    "_P = store[pd.isnull(store.Promo2SinceWeek)]\n",
    "_P[_P.Promo2 != 0].shape\n",
    "\n",
    "# Replace NA's with 0\n",
    "store = store.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove closed and open stores with no sales\n",
    "train = train[(train['Open'] != 0) & (train['Sales'] != 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Year'] = train.index.year\n",
    "train['Month'] = train.index.month\n",
    "train['Day'] = train.index.day\n",
    "train['WeekOfYear'] = train.index.weekofyear\n",
    "\n",
    "# New variable\n",
    "train['SalePerCustomer'] = train['Sales']/train['Customers']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining train data with additional store information\n",
    "\n",
    "train_reset = train.reset_index()\n",
    "store_train = pd.merge(train_reset, store, how = 'inner', on = 'Store')\n",
    "store_train.head()\n",
    "store_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "cat_to_num_col = ['StateHoliday', 'StoreType', 'Assortment']\n",
    "new_col = ['State_Holiday', 'Store_Type', 'Assort_ment']\n",
    "for i in range(0, len(cat_to_num_col)):\n",
    "    store_train[new_col[i]] = LE.fit_transform(store_train[cat_to_num_col[i]])\n",
    "    store_train = store_train.drop(cat_to_num_col[i], axis = 1)\n",
    "\n",
    "store_train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_85 = store_train[store_train['Store'] == 85].sort_index(ascending = False).reset_index().drop('index', axis = 1)\n",
    "store_85_sales = store_85.loc[:, ['Date','Sales']]\n",
    "store_85_sales['Date'] = pd.DatetimeIndex(store_85_sales['Date'])\n",
    "#store_85.head()\n",
    "store_85_sales.head()\n",
    "store_85_sales.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'Open' variable\n",
    "corr_all = store_train.drop('Open', axis = 1).corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr_all, dtype = np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize = (11, 9))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_all, mask = mask,\n",
    "            square = True, linewidths = .5, ax = ax, cmap = \"BuPu\")      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer per day trend based on Store type\n",
    "\n",
    "sns.pointplot(x = 'DayOfWeek', y = 'Customers', hue = 'Store_Type', \n",
    "            col = 'Store', col_wrap = 3, data = store_train,\n",
    "            palette = 'RdBu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale per day trend based on Store type\n",
    "\n",
    "sns.pointplot(x = 'DayOfWeek', y = 'Sales', hue = 'Store_Type', \n",
    "            col = 'Store', col_wrap = 3, data = store_train,\n",
    "            palette = 'plasma') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale per day trend based on Promo2\n",
    "\n",
    "sns.pointplot(x = 'DayOfWeek', y = 'Sales', hue = 'Promo2', \n",
    "            data = store_train, palette = 'RdPu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sale per day trend based on Promo\n",
    "\n",
    "sns.pointplot(x = 'DayOfWeek', y = 'Sales', hue = 'Promo', \n",
    "            data = store_train, palette = 'RdGy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average daily sales per week \n",
    "f, (ax1, ax2) = plt.subplots(2, figsize = (10, 8))\n",
    "\n",
    "date_sales_cust = store_train[['Date', 'Sales', 'Customers']].groupby(pd.Grouper(key='Date', freq='7D')).mean()\n",
    "ax1.plot(date_sales_cust.index, date_sales_cust.Sales, color = 'm')\n",
    "ax2.plot(date_sales_cust.index, date_sales_cust.Customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time-series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation: input should be float type\n",
    "train['Sales'] = train['Sales'] * 1.0\n",
    "\n",
    "# store types to represent the group\n",
    "sales_a = train[train.Store == 2]['Sales']\n",
    "sales_b = train[train.Store == 85]['Sales'] # .sort_index(ascending = True)... solve the reverse order\n",
    "sales_c = train[train.Store == 1]['Sales']\n",
    "sales_d = train[train.Store == 13]['Sales']\n",
    "\n",
    "# Downsampling data from days to weeks\n",
    "sales_a_re = sales_a.resample('W').sum()\n",
    "sales_b_re = sales_b.resample('W').sum()\n",
    "sales_c_re = sales_c.resample('W').sum()\n",
    "sales_d_re = sales_d.resample('W').sum()\n",
    "\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 13))\n",
    "\n",
    "ax1.plot(sales_a_re, color = 'y')\n",
    "ax2.plot(sales_b_re, color = 'b')\n",
    "ax3.plot(sales_c_re, color = 'm')\n",
    "ax4.plot(sales_d_re, color = 'c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yearly trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize = (12, 15))\n",
    "\n",
    "# monthly\n",
    "decomposition_a = seasonal_decompose(sales_a, model = 'additive', freq = 365)\n",
    "decomposition_a.trend.plot(color = 'c', ax = ax1)\n",
    "\n",
    "decomposition_b = seasonal_decompose(sales_b, model = 'additive', freq = 365)\n",
    "pd.plotting.register_matplotlib_converters()\n",
    "decomposition_b.trend.plot(color = 'm', ax = ax2)\n",
    "\n",
    "decomposition_c = seasonal_decompose(sales_c, model = 'additive', freq = 365)\n",
    "decomposition_c.trend.plot(color = 'k', ax = ax3)\n",
    "\n",
    "decomposition_d = seasonal_decompose(sales_d, model = 'additive', freq = 365)\n",
    "decomposition_d.trend.plot(color = 'y', ax = ax4)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_85_train, store_85_test = train_test_split(store_85, test_size = 0.33, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_85_sales_train, store_85_sales_test = train_test_split(store_85_sales, test_size = 0.33, random_state = 33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(df_test, df_predict):\n",
    "    errors = abs(df_predict - df_test)\n",
    "    \n",
    "    Mae = round(np.mean(errors), 2)\n",
    "    mape = 100 * (errors/df_test)\n",
    "    rmspe = round(100 * np.sqrt(np.mean((1 - df_predict/ df_test) ** 2)), 2)\n",
    "    \n",
    "    accuracy = round(100 - np.mean(mape), 2)\n",
    "    \n",
    "    list = [rmspe, accuracy]\n",
    "    #print('Root MSE %:', rmspe)\n",
    "    #print('Accuracy %:', accuracy)\n",
    "    \n",
    "    return(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fbProphet Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Holidays df for Prophet\n",
    "\n",
    "state_dates = store_train[(store_train.State_Holiday == 'a') | (store_train.State_Holiday == 'b') & \n",
    "                          (store_train.State_Holiday == 'c')].loc[:, 'Date'].values\n",
    "school_dates = store_train[(store_train.SchoolHoliday == 1)].loc[:, 'Date'].values\n",
    "\n",
    "state = pd.DataFrame({'holiday' : 'state_holiday', 'ds' : pd.to_datetime(state_dates)})\n",
    "school = pd.DataFrame({'holiday' : 'school_holiday', 'ds' : pd.to_datetime(school_dates)})\n",
    "\n",
    "holidays = pd.concat((state,school))\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_train = store_85_sales_train.rename(columns = {'Date' : 'ds', 'Sales' : 'y'})\n",
    "prophet_test = store_85_sales_test.rename(columns = {'Date' : 'ds', 'Sales' : 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting uncertainty interval to 95%\n",
    "\n",
    "prophet_model = Prophet(interval_width = 0.95, holidays = holidays)\n",
    "prophet_model.fit(prophet_train)\n",
    "\n",
    "# Dataframe for forecasting 6 weeks \n",
    "# prophet_future_dates = prophet_model.make_future_dataframe(periods = 6*7)\n",
    "# prophet_future_dates.tail(7)\n",
    "\n",
    "prophet_forecast = prophet_model.predict(prophet_test)\n",
    "prophet_forecast = prophet_forecast[['ds', 'yhat']]\n",
    "prophet_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_df_test = prophet_test.sort_values(by = 'ds', ascending = True).reset_index().drop('index', axis = 1).y\n",
    "prophet_df_predict = prophet_forecast.sort_values(by = 'ds', ascending = True).yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy(prophet_df_test, prophet_df_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression - OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_exclude_columns = ['Date', 'PromoInterval', 'Sales', 'SalePerCustomer']\n",
    "LR_target_column = 'Sales'\n",
    "LR_feature_columns = [i for i in store_train.columns.values if i not in LR_exclude_columns]\n",
    "\n",
    "LR_input_data = pd.DataFrame(store_train, columns = LR_feature_columns)\n",
    "LR_input_data_np = np.asarray(LR_input_data)\n",
    "LR_input_data = sm.add_constant(LR_input_data_np, has_constant = 'add')\n",
    "LR_target_data = pd.DataFrame(store_train, columns = [LR_target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = sm.OLS(LR_target_data, LR_input_data).fit()\n",
    "#LR_model.params\n",
    "LR_model.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression - Scikit_learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_feature_train = store_85_train[[i for i in LR_feature_columns]]\n",
    "LR_target_train = store_85_train[['Sales']]\n",
    "\n",
    "LR_regressor = LinearRegression()\n",
    "LR_regressor.fit(LR_feature_train, LR_target_train)\n",
    "\n",
    "print(LR_regressor.intercept_)\n",
    "print(LR_regressor.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_feature_test = store_85_test[[i for i in LR_feature_columns]]\n",
    "LR_target_test = store_85_test[['Sales']]\n",
    "\n",
    "LR_predictions = LR_regressor.predict(LR_feature_test)\n",
    "LR_forecast = pd.DataFrame({'Actual': LR_target_test.Sales, \n",
    "                            'Predicted': LR_predictions.flatten()}).reset_index().drop('index', axis = 1)\n",
    "LR_forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy(LR_forecast.Actual, LR_forecast.Predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_exclude_columns = ['Sales', 'Date', 'PromoInterval', 'SalePerCustomer', 'Year', 'Day', 'Month',\n",
    "                     'DayOfWeek', 'WeekOfYear']\n",
    "NN_target_column = 'Sales'\n",
    "NN_feature_columns = [i for i in store_train.columns.values if i not in NN_exclude_columns]\n",
    "\n",
    "MM_sc = MinMaxScaler()\n",
    "    \n",
    "#store_85_train, store_85_test = train_test_split(store_85, test_size = 0.33, random_state = 33)\n",
    "NN_input_train = MM_sc.fit_transform(store_85_train[[i for i in NN_feature_columns]])\n",
    "NN_input_test = MM_sc.fit_transform(store_85_test[[i for i in NN_feature_columns]])\n",
    "NN_target_train = store_85_train[['Sales']].values.reshape(-1,1)\n",
    "NN_target_test = store_85_test[['Sales']].values.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regressor(activation = 'relu', optimizer = 'adam'):\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim = 14, kernel_initializer = 'normal', activation = activation))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal'))\n",
    "    \n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "activations = ['relu', 'tanh']\n",
    "optimizers = ['sgd', 'adam', 'rmsprop']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for o in range(len(optimizers)):\n",
    "    for a in range(len(activations)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params_NN(pair):\n",
    "    \n",
    "    o,a = pair\n",
    "    \n",
    "    optimizer = optimizers[o]\n",
    "    activation = activations[a]\n",
    "    \n",
    "    cols = ['Activation','Optimizer','Epochs', 'Batch', 'rmspe', 'accuracy']\n",
    "    acc = pd.DataFrame(columns = cols)\n",
    "\n",
    "    for i in range(1,10):\n",
    "        for j in range(100, 500, 100):\n",
    "        \n",
    "            NN_estimator = KerasRegressor(build_fn = build_regressor, epochs = j, batch_size = i, verbose = 0)\n",
    "            NN_estimator.fit(NN_input_train, NN_target_train)\n",
    "    \n",
    "            NN_predictions = pd.DataFrame(NN_estimator.predict(NN_input_test))\n",
    "            #NN_target_test[NN_target_test == 0] = np.mean(NN_target_test)\n",
    "            #NN_predictions.values[NN_predictions.values == 0] = np.mean(NN_predictions)\n",
    "        \n",
    "            accuracy = Accuracy(NN_target_test, NN_predictions)\n",
    "            acc = acc.append({'Activation': activation, 'Optimizer': optimizer,'Epochs': j, 'Batch': i, \n",
    "                                'rmspe': accuracy[0], 'accuracy': accuracy[1]}, ignore_index = True)\n",
    "        #print(Accuracy(NN_target_test, NN_predictions))\n",
    "    \n",
    "    #best_params_index = acc[acc['accuracy'] == acc['accuracy'].max()].index\n",
    "        \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallelizing using pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "    \n",
    "pool = Pool(mp.cpu_count())\n",
    "    \n",
    "arg_pairs = [(o,a) for o in range(len(optimizers)) for a in range(len(activations))]\n",
    "results = pool.map(best_params_NN, arg_pairs)\n",
    "    \n",
    "pool.close()\n",
    "pool.join()\n",
    "    \n",
    "    # results = pool.starmap(best_params_NN,[(store_train, store_85)])\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_feature_train = store_85_train[[i for i in LR_feature_columns]]\n",
    "RF_target_train = store_85_train[['Sales']]\n",
    "\n",
    "RF_feature_test = store_85_test[[i for i in LR_feature_columns]]\n",
    "RF_target_test = store_85_test[['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model = RandomForestRegressor(n_estimators = 50, random_state = 50)\n",
    "RF_model.fit(RF_feature_train, RF_target_train.values.ravel())\n",
    "\n",
    "RF_predictions = pd.DataFrame(RF_model.predict(RF_feature_test))\n",
    "RF_target_test.values[RF_target_test.values == 0] = np.mean(RF_target_test)\n",
    "RF_predictions.values[RF_predictions.values == 0] = np.mean(RF_predictions)\n",
    "\n",
    "Accuracy(RF_target_test.values, RF_predictions.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_feature_imp = list(RF_model.feature_importances_)\n",
    "indices = np.argsort(RF_feature_imp)\n",
    "features_ranked = []\n",
    "\n",
    "for f in range(RF_feature_train.shape[1]):\n",
    "    features_ranked.append(RF_feature_train.columns[indices[f]])\n",
    "\n",
    "# features_ranked\n",
    "RF_important = pd.Series(data = RF_feature_imp, index = indices).sort_index().tolist()\n",
    "np.array(RF_important)\n",
    "np.array(RF_feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
